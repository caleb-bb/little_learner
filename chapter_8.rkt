#lang racket
(require malt)

(declare-hyper mu)

;; (- (* alpha g)) => (+ (* mu v) (- (* alpha g)))
;; == (+ (* mu alpha g_0) (- (* alpha g_1)))

;; for a tensor of shape (s1 s2 s3 ... sn), (zeroes that_tensor) produces a
;; tensor of that exact shape, where all 0-rank tensors in sn are equal to 0.0 this
;; is our "inflate" function, which turns an unaccompanied parameter, p,into an
;; accompanied parameter. In this case, we expect a tensor, and we wrap it in a
;; list with a zeroed-out tensor of the same shape
;;
;; We begin with a zeroed-out tensor because, at the first revision, nothing has
;; changed. So the product of mu and previous velocity should be 0 because there IS
;; NO previous velocity
;; Notice how the inflated version of our parameter is the original tensor plus a
;; zeroed-out version of itself. That means that our original parameter is
;; ACCOMPANIED by a fraction of the previous velocity, which is zero in this case.
;;
;; To try and get my head above water here: the big_theta consists of a tensor
;; and the fraction of the previous velocity we want to multiply it by. That's
;; because right now, we're using momentum to push the gradient descent along
;; faster, and momentum is defined by that previous velocity. Accordingly, our
;; update function (which gets passed to revise) needs to know what that previous
;; velocity is. It follows that that previous velocity should ACCOMPANY the
;; velocity under revision.

;; To get out of the water completely: gradient-descent takes a data set,
;; inflates it with whatever extra parameters the update function needs, applies
;; the update function a buncha times, then deflates it back. Since our update
;; function needs a bunch of extra shit to update stuff, the tensor it operates on
;; will have a different shape (probably) than the one that gets passed in. It
;; follows that we need some way to change the tensor's shape so that we can
;; revise its weights, and then change its shape back when we're done revising.
;; Bada-BOOM!

;; Now, from the top: gradient descent takes a data set and revises it until the
;; outputss generated by that data set (when given to some higher-order function)
;; match the set of desired outputs.
;;
;; Gradient descent does that like this:
;; 1. Calculate the gradient for the set of weights (the gradient has a separate value for each weight)
;; 2. Feed both the current weight and its gradient to an update function that knows how to update the weight
;; 3. Return to step 1 unless some condition is met.
;;
;; There's a catch, though. See, sometimes the function we use to update the
;; weight is really complicated. And it needs stuff besides just the original
;; weight. So we have to pass in the original weight, plus some other parameters
;; and/or hyperparameters. We might create some of those other things on the fly.
;; As a result, the tensor we pass into the update function might have a different
;; shape than the original tensor comprising the weights.
;;
;; That means that, once we're done revising the dataset by updating each
;; weight, we need some way to change its shape back to the way it originally was.
;; So we need a "deflating" function as well.

(define velocity-i (lambda (p) (list p (zeroes p))))

;; velocity-d is our deflationary function. It takes big_p (a big_theta) as a
;; parameter and unwraps it to return a p.
(define velocity-d (lambda (big_p) (ref big_p 0)))

;; velocity-u is our update function. It takes a big_p parameter, which contains
;; the current weight and the velocity of the prior weight. It also takes a
;; gradient. It revises the big_p via the usual method of subtracting the product
;; of the gradient and the learning rate. However, this function contains a
;; hyper-parameter, mu, which is multiplied by the previous velocity. Mu is some
;; number between 0 and 1. Typically ~0.9

(define velocity-u
  (lambda (big_p g) (let ([v (- (* mu (ref big_p 1)) (* alpha g))]) (list (+ (ref big_p 0) v) v))))

(define velocity-gradient-descent (gradient-descent velocity-i velocity-d velocity-u))

(define plane-xs
  (tensor (tensor 1.0 2.05)
          (tensor 1.0 3.0)
          (tensor 2.0 2.0)
          (tensor 2.0 3.9)
          (tensor 3.0 6.13)
          (tensor 4.0 8.09)))

(define plane-ys (tensor 13.99 15.99 18.0 22.4 30.2 37.94))

(define try-plane
  (lambda (a-gradient-descent a-revs)
    (with-hypers [(revs a-revs) (alpha 0.001) (batch-size 4)]
                 (a-gradient-descent (sampling-obj (l2-loss plane) plane-xs plane-ys)
                                     (list (tensor 0.0 0.0) 0.0)))))

(with-hypers ((mu 0.8)) (try-plane velocity-gradient-descent 5000))
